自注意力机制可以简单的理解为对每一个像素点进行注意力权重分配



query和key可以理解为一个矩阵的可以相乘的形式，两个矩阵相乘可以理解为每一个像素在整个图像的层面所占的数值更大，所占的比重比之前更大，可能这就是自注意力机制的原理。

过softmax会把每行的像素进行权重分配（每一行像素的权重之和为1）

